# app.py
import json
import requests
import streamlit as st
import pandas as pd

# =========================
# App config
# =========================
st.set_page_config(page_title="SNOWì±—ë´‡ (Cortex Agents)", page_icon="â„ï¸", layout="wide")
st.title("â„ï¸ SNOWì±—ë´‡ - Cortex Agents (PAT + REST)")
st.caption("Snowflake Agents + Analyst + Search (Community Cloud)")

# =========================
# Secrets / constants
# =========================
SF = st.secrets["snowflake"]

# REST í˜¸ì¶œìš©
ACCOUNT_BASE = SF["account_base"]  # ì˜ˆ: https://fv93338.ap-northeast-2.aws.snowflakecomputing.com
PAT          = SF["pat"]           # Programmatic Access Token
ROLE         = SF.get("role", "SALES_INTELLIGENCE_RL")
WAREHOUSE    = SF.get("warehouse", "SALES_INTELLIGENCE_WH")
DATABASE     = SF.get("database",  "SALES_INTELLIGENCE")
SCHEMA       = SF.get("schema",    "DATA")

# (ì„ íƒ) SQL ì‹¤í–‰ìš© ì»¤ë„¥í„° ìê²©
SF_USER      = SF.get("user")
SF_PASSWORD  = SF.get("password")
SF_ACCOUNT   = SF.get("account")   # ì˜ˆ: fv93338.ap-northeast-2.aws

# ëª¨ë¸(ì„œìš¸ë¦¬ì „ ë¯¸ì œê³µ ê°€ëŠ¥ â†’ Cross-Region í—ˆìš© ì‹œ ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸ë¡œ ì„ íƒ)
MODEL_NAME   = st.sidebar.selectbox("Model", ["llama3.3-70b", "mistral-large2"], index=0)

# ë¦¬ì†ŒìŠ¤ ì´ë¦„(ëŒ€ë¬¸ì/í’€ë„¤ì„ ê¶Œì¥)
CORTEX_SEARCH_SERVICE = "SALES_INTELLIGENCE.DATA.SALES_CONVERSATION_SEARCH"
SEMANTIC_MODEL_FILE   = "@SALES_INTELLIGENCE.DATA.MODELS/sales_metrics_model.yaml"

API_ENDPOINT = f"{ACCOUNT_BASE}/api/v2/cortex/agent:run"

# =========================
# Helpers
# =========================
def build_headers():
    return {
        "Authorization": f"Bearer {PAT}",
        "Accept": "application/json",  # JSON ëª¨ë“œ(ë¹„ìŠ¤íŠ¸ë¦¬ë°)
        "Content-Type": "application/json",
        "X-Snowflake-Authorization-Token-Type": "PROGRAMMATIC_ACCESS_TOKEN",
        "X-Snowflake-Role": ROLE,
        "X-Snowflake-Database": DATABASE,
        "X-Snowflake-Schema": SCHEMA,
        "X-Snowflake-Warehouse": WAREHOUSE,
    }

def build_payload(user_text: str, max_results: int = 5):
    return {
        "model": MODEL_NAME,
        "messages": [
            {"role": "user", "content": [{"type": "text", "text": user_text}]}
        ],
        "tools": [
            {"tool_spec": {"type": "cortex_analyst_text_to_sql", "name": "analyst1"}},
            {"tool_spec": {"type": "cortex_search", "name": "search1"}}
        ],
        "tool_resources": {
            "analyst1": {"semantic_model_file": SEMANTIC_MODEL_FILE},
            "search1": {
                "name": CORTEX_SEARCH_SERVICE,
                "max_results": max_results,
                "id_column": "conversation_id"
            }
        }
    }

def _pull_from_tool_result(result_obj, citations, set_sql_fn):
    """tool_results í•œ ë©ì–´ë¦¬ì—ì„œ sql / citations ì¶”ì¶œ"""
    if not isinstance(result_obj, dict):
        return
    j = result_obj.get("json")
    if isinstance(j, str):
        try:
            j = json.loads(j)
        except Exception:
            j = None
    if not isinstance(j, dict):
        return

    # SQL í‚¤ ì´ë¦„ í›„ë³´ë“¤ ëª¨ë‘ ìŠ¤ìº”
    for k in ("sql", "generated_sql", "sql_query"):
        if isinstance(j.get(k), str) and j[k].strip():
            set_sql_fn(j[k])
            break

    # ê²€ìƒ‰ ì¸ìš© ê²°ê³¼
    sr = j.get("searchResults") or j.get("results") or []
    if isinstance(sr, list):
        for s in sr:
            if isinstance(s, dict):
                citations.append({
                    "source_id": s.get("source_id", ""),
                    "doc_id": s.get("doc_id", "") or s.get("id", "")
                })

def parse_agent_json(obj):
    """
    JSON ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸/SQL/ì¸ìš©ì„ ìµœëŒ€í•œ í­ë„“ê²Œ ì¶”ì¶œ
    return (text, sql, citations)
    """
    text_parts = []
    citations = []
    sql_holder = {"v": None}

    def set_sql(v: str):
        if v and isinstance(v, str) and v.strip():
            sql_holder["v"] = v

    # content ë°°ì—´ì—ì„œ text/tool_resultsë¥¼ ê¸ì–´ì˜¤ëŠ” ë‚´ë¶€ í•¨ìˆ˜
    def pull_from_content(content):
        if isinstance(content, dict):
            content = [content]
        if not isinstance(content, list):
            return
        for item in content:
            if not isinstance(item, dict):
                continue
            t = item.get("type")
            if t == "text":
                txt = item.get("text")
                if isinstance(txt, str) and txt:
                    text_parts.append(txt)
            elif t == "tool_results":
                tr = item.get("tool_results", {})
                for r in tr.get("content", []):
                    _pull_from_tool_result(r, citations, set_sql)

    # 1) í”í•œ ë£¨íŠ¸ í‚¤ë“¤ í›‘ê¸°
    for key in ("output", "message", "response", "data"):
        node = obj.get(key)
        if isinstance(node, dict) and "content" in node:
            pull_from_content(node["content"])

    # 2) ë£¨íŠ¸ì— contentê°€ ë°”ë¡œ ìˆì„ ìˆ˜ë„
    if not text_parts and "content" in obj:
        pull_from_content(obj["content"])

    # 3) ê·¸ë˜ë„ ì—†ìœ¼ë©´ ì „ì²´ dict ê¹Šê²Œ í›‘ì–´ì„œ content í›„ë³´ ì°¾ê¸°(ë°©ì–´ì )
    if not text_parts and sql_holder["v"] is None:
        def deep_walk(x):
            if isinstance(x, dict):
                if "content" in x:
                    pull_from_content(x["content"])
                for v in x.values():
                    deep_walk(v)
            elif isinstance(x, list):
                for v in x:
                    deep_walk(v)
        deep_walk(obj)

    text = "\n\n".join(text_parts).strip()
    return text, sql_holder["v"], citations

# =========================
# (ì„ íƒ) ìƒì„±ëœ SQL ì‹¤í–‰ ì§€ì›
# =========================
@st.cache_resource
def get_sql_connection():
    """í•„ìš”ì‹œì—ë§Œ ì—°ê²°. user/password/accountê°€ ëª¨ë‘ ìˆì„ ë•Œë§Œ."""
    import snowflake.connector  # lazy import
    if not (SF_USER and SF_PASSWORD and SF_ACCOUNT):
        return None
    return snowflake.connector.connect(
        user=SF_USER,
        password=SF_PASSWORD,
        account=SF_ACCOUNT,   # ì˜ˆ: fv93338.ap-northeast-2.aws
        warehouse=WAREHOUSE,
        database=DATABASE,
        schema=SCHEMA,
        role=ROLE,
        session_parameters={"CLIENT_SESSION_KEEP_ALIVE": True},
    )

def run_sql_in_snowflake(sql: str) -> pd.DataFrame | None:
    conn = get_sql_connection()
    if conn is None:
        st.info("ğŸ” secretsì— user/password/accountê°€ ì—†ì–´ SQL ì‹¤í–‰ì€ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None
    try:
        with conn.cursor() as cur:
            cur.execute(sql)
            rows = cur.fetchall()
            cols = [d[0] for d in cur.description]
            return pd.DataFrame(rows, columns=cols)
    except Exception as e:
        st.error(f"âŒ SQL ì‹¤í–‰ ì—ëŸ¬: {e}")
        st.code(sql, language="sql")
        return None

# =========================
# Session state / Sidebar
# =========================
if "messages" not in st.session_state:
    st.session_state.messages = []

with st.sidebar:
    st.header("Settings")
    max_results = st.slider("Max search results", 1, 10, 5)
    do_run_sql = st.checkbox("Execute generated SQL", value=False)
    if st.button("New Conversation"):
        st.session_state.messages = []
        st.rerun()

# =========================
# Chat history
# =========================
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# =========================
# Input & Call
# =========================
query = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: How many deals did Sarah Johnson win compared to lost?)")
if query:
    st.session_state.messages.append({"role": "user", "content": query})
    with st.chat_message("user"):
        st.markdown(query)

    with st.spinner("Calling Snowflake Agents..."):
        payload = build_payload(query, max_results=max_results)
        resp = requests.post(API_ENDPOINT, headers=build_headers(), data=json.dumps(payload))

    # ---- ì—ëŸ¬ ì²˜ë¦¬ ----
    if resp.status_code != 200:
        st.error(f"HTTP {resp.status_code} â€” {resp.reason}")
        try:
            st.code(resp.text[:2000], language="json")
        except Exception:
            st.text(resp.text[:2000])
    else:
        # JSON ë°”ë”” íŒŒì‹±
        try:
            body = resp.json()
        except Exception:
            body = None

        if not body:
            st.warning("ì‘ë‹µ ë³¸ë¬¸ì´ ë¹„ì—ˆìŠµë‹ˆë‹¤.")
            st.code(resp.text[:2000], language="json")
        else:
            text, sql, cites = parse_agent_json(body)

            # 1) ë‹µ í…ìŠ¤íŠ¸
            if text:
                text = text.replace("ã€â€ ", "[").replace("â€ ã€‘", "]")
                st.session_state.messages.append({"role": "assistant", "content": text})
                with st.chat_message("assistant"):
                    st.markdown(text)
            else:
                st.warning("ì‘ë‹µ í…ìŠ¤íŠ¸ê°€ ì—†ì–´ ë¶„ì„ ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")

            # 2) ìƒì„±ëœ SQL
            if sql:
                st.markdown("### Generated SQL")
                st.code(sql, language="sql")

                # ì„ íƒ ì‹œ ì‹¤ì œ ì‹¤í–‰
                if do_run_sql:
                    df = run_sql_in_snowflake(sql)
                    if df is not None:
                        st.dataframe(df, use_container_width=True)
                        if not text:
                            with st.chat_message("assistant"):
                                st.markdown("í…ìŠ¤íŠ¸ ì‘ë‹µì€ ì—†ì–´ SQL ê²°ê³¼ë¥¼ í‘œì‹œí–ˆì–´ìš”.")
            else:
                if not text:
                    st.info("í…ìŠ¤íŠ¸/SQL ëª¨ë‘ ì—†ì–´ Raw ì‘ë‹µì„ í‘œì‹œí•©ë‹ˆë‹¤.")
                    st.code(json.dumps(body, ensure_ascii=False, indent=2)[:2000], language="json")

            # 3) Citations
            if cites:
                st.markdown("### Citations")
                st.dataframe(pd.DataFrame(cites), use_container_width=True)

# =========================
# Footer
# =========================
st.markdown("---")
st.caption("Â© 2025 HDC DataLab Â· Streamlit + Snowflake Cortex Agents (PAT)")
